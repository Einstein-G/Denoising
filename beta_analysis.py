import tifffile.tifffile as tiff
import numpy as np
from random import uniform
from numpy.fft import fft2, fftshift, ifftshift, ifft2
from skimage import img_as_ubyte
from skimage.exposure import equalize_adapthist
from skimage.filters import threshold_otsu
from skimage.morphology import remove_small_objects
from scipy.signal import medfilt
from scipy.io import loadmat
from multiprocessing import Pool
import matplotlib.pyplot as plt
from functools import partial
import argparse
import ast
import json
import tqdm
def load(path):
    """Load images with given path and return Numpy array"""
    if path.endswith('.tiff') | path.endswith('.tif'):
        data = tiff.imread(path)
    else:
        raise Exception('File format not supported')
    if len(data.shape) == 2:
        data = np.atleast_3d(data)
        data = np.transpose(data, (2, 0, 1))
    return data

def createcircularmask(h, w, center=None, radius=None):

    if center is None: # use the middle of the image
        center = [int(w/2), int(h/2)]
    if radius is None: # use the smallest distance between the center and image walls
        radius = min(center[0], center[1], w-center[0], h-center[1])

    Y, X = np.ogrid[:h, :w]
    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)

    mask = dist_from_center <= radius
    return mask

def rand(x):
    x = x/2
    return round(uniform(-x, x))

def clonestampzeros(img):
    size = img.shape
    for i in range(100):
        rn=rand(size[0])
        rn2=rand(size[1])
        img2 = np.roll(img, [rn, rn2])
        img = np.where(img==0, img2, img)
        if not np.any(img == 0):
            break
    return img

def gaussian_bandpass(shape, low_f, high_f):
    """Gaussian band pass filter high_f and low_f are cutoff frequencies"""
    nx, ny = shape
    width = 2*nx-1
    height = 2*ny-1

    i = np.arange(width)
    j = np.arange(height)
    ii, jj = np.meshgrid(i,j)
    dist = np.sqrt((ii-nx)**2 + (jj-ny)**2)
    # gaussian filters
    lowpass = np.exp(-dist**2/(2*high_f**2))
    highpass = 1 - np.exp(-dist**2/(2*low_f**2))
    filter_coeffs = lowpass*highpass
    return filter_coeffs

def butterworth_bandpass(shape, low_f, high_f, n):
    """Butterworth band pass filter high_f and low_f are cutoff frequencies
    n is order"""
    nx, ny = shape
    width = 2*nx-1
    height = 2*ny-1

    i = np.arange(width)
    j = np.arange(height)
    ii, jj = np.meshgrid(i,j)
    dist = np.sqrt((ii-nx)**2 + (jj-ny)**2)
    # butterworth filters
    lowpass = 1/(1 + (dist/high_f)**(2*n))
    highpass = 1 - 1/(1 + (dist/low_f)**(2*n))
    filter_coeffs = lowpass*highpass
    return filter_coeffs

def apply_filter(img, filter_coeffs): # I wish i could use just "filter" but that's a keyword, oh well.
    """Apply filters generated by functions in this module"""
    nx, ny = img.shape
    width = 2*nx-1
    height = 2*ny-1
    fftI = fft2(img, (width, height))
    fftI = fftshift(fftI)
    filtered = fftI + filter_coeffs*fftI
    filtered = ifftshift(filtered)
    filtered = ifft2(filtered, (width, height))
    filtered = np.real(filtered[0:nx, 0:ny])
    return filtered

def calc_psd_rad(img):
    """Calculate radial PSD from an image. This function was written originally 
    by Kyle Quinn (and sorry, but it was horrible). So I just translated it to Python 
    with minimal knowledge of its interworkings. This greatly limits my ability to
    optimize it."""

    def calc_xc_yc(img):
        x,y = img.shape
        x = np.arange(x)
        y = np.arange(y)
        xx, yy = np.meshgrid(x, y)
        xc = -xx + np.mean(xx)
        yc = yy - np.mean(yy)
        return xc, yc

    def cart2pol(x, y):
        rho = np.sqrt(x**2 + y**2)
        phi = np.arctan2(y, x)
        return(rho, phi)

    xc, yc = calc_xc_yc(img)
    img = img/np.max(img)
    img = np.hstack((img, np.fliplr(img)))
    img = np.vstack((img, np.flipud(img)))

    xc, yc = calc_xc_yc(img)
    rho, theta = cart2pol(xc,yc)
    ang = (theta - np.pi/2).flatten()
    rad = rho.flatten()

    # filter pixels that are inside square
    condition = rad < np.max(xc)+.5
    ang = np.extract(condition, ang)
    rad = np.extract(condition, rad)

    f = 1
    dr = np.round(rad/f)*f
    vals = np.arange(f,np.max(xc)+0.5+f,f)

    L = img.shape[0]
    shgfft = fft2(img)
    y1 = fftshift(shgfft)
    psd1 = y1*np.conj(y1)/L/L
    ff = psd1.flatten('F')
    ff = np.extract(condition, ff)

    psd = np.zeros(vals.shape[0])
    for j in range(vals.shape[0]):
        condition = dr == vals[j]
        ff2 = np.extract(condition, ff)
        psd[j] = np.mean(ff2)

    freq = (1/L)*np.arange(1, L/2-1)
    psd = psd[1:]

    return psd, freq

###############################################################################################################

def mask_img(img, thresh_multiplier):
    # histogram equalization
    img = equalize_adapthist(img, clip_limit=0.01)
    # otsu's method global thresholding
    global_thresh = threshold_otsu(img)*thresh_multiplier
    img = img > global_thresh
    # 2D median filtering
    img = medfilt(img, 3).astype(bool)
    return img


def mask_stack(stack, thresh_multiplier=1):
    #stack = img_as_ubyte(stack)
    p_mask_img = partial(mask_img, thresh_multiplier=thresh_multiplier)
    #with Pool() as p:
    stack = np.array(list(map(p_mask_img, stack)))
    return stack


def process_img(img, num_hists, thresh_multiplier, filters=None):
    for x in range(num_hists):
        img = equalize_adapthist(img, clip_limit=0.01)
    for f in filters:
        img = apply_filter(img, f)
    img = img-np.amin(img)
    img = img/np.amax(img)
    global_thresh = thresh_multiplier*threshold_otsu(img)
    img = img > global_thresh
    return img

def remove_nuclei_intercellular_space(tpef, num_hists=4, thresh_multiplier=1):
    shape = tpef.shape[1:]
    filters = (gaussian_bandpass(shape, 25, 256),
            gaussian_bandpass(shape, 20, 120),
            butterworth_bandpass(shape, 10,120,3))
    p_process_img = partial(process_img, num_hists=num_hists, thresh_multiplier=thresh_multiplier, filters=filters)
    #with Pool() as p:
    stack = np.array(list(map(p_process_img, tpef)))
    return stack

def preprocess(tpef, shg=None, level1=1, level2=1, num_hists=1,make_circular=False):
    """Preprocess TPEF stack for beta analysis"""
    tpef = np.copy(tpef)
    sandbag = mask_stack(tpef, thresh_multiplier=level1)
    BW = remove_nuclei_intercellular_space(tpef,num_hists=num_hists, thresh_multiplier=level2)
    if shg is not None:
        shg = mask_stack(shg)
        mask = np.logical_and.reduce((BW, ~shg, ~sandbag))
    else:
        mask = np.logical_and.reduce((BW, ~sandbag))
    # remove small binary objects
    remove_small_objects(mask, min_size=10, connectivity=8, in_place=True)
    tpef[~mask] = 0
    if make_circular:
        w = tpef.shape[1]
        h = tpef.shape[2]
        circularmask = createcircularmask(h,w)
        _,circularmask3d = np.broadcast_arrays(tpef, circularmask[None,...])
        tpef[~circularmask3d] = 0

def p_calc_psd_rad(img):
    return calc_psd_rad(img)[0]

def analyze(tpef, num_clones=5):
    """Apply beta analysis to fluorescence image(s). Optional: take SHG into account"""
    shape = np.hstack((num_clones, tpef.shape[0], tpef.shape[-1]-1)) #this assumes square
    psds = np.zeros(shape)
    '''
    with Pool(processes = 10) as p:
        for k in range(num_clones):
            clone_stamped = np.array([clonestampzeros(img) for img in tpef]) #too quick to be worth parallelizing
            mapped = p.map_async(p_calc_psd_rad, clone_stamped)
            mapped.wait()
            psds[k,:] = np.array(list(mapped))
            
    '''

    def tmp(tpef):
        return [clonestampzeros(img) for img in tpef]

    with Pool(processes=10) as p:
        #for k in range(num_clones):
        #    clone_stamped = np.array([clonestampzeros(img) for img in tpef]) #too quick to be worth parallelizing
        #    psds[k,:] = np.array(p.map(p_calc_psd_rad, clone_stamped))
        multiple_results = [p.map_async(p_calc_psd_rad,np.array(tmp(tpef))) for k in range(num_clones)]
        #results=  
        #for res in multiple_results:
        #    for r in res:
        multiple_results =[res.get() for res in multiple_results]

    
    for k in range(num_clones):
        psds[k,:] = multiple_results[k]

    psd_mean = np.mean(psds, axis=0)
    L = tpef.shape[-1]*2
    freq = (1/L)*np.arange(1, L/2-1)

    pixnum = 8.5/200*512
    f1num = 1/pixnum;
    f1 = np.argwhere(freq>f1num)[0].item()

    beta = np.zeros(tpef.shape[0])
    for i in tqdm.tqdm(range(tpef.shape[0])):
        maxpsd = np.max(np.log10(psd_mean[i,:]))
        minpsd = np.min(np.log10(psd_mean[i,:]))
        thr = 10**(maxpsd - 0.98*(maxpsd-minpsd))
        psd_i = psd_mean[i,:]
        f2 = np.argwhere(psd_i<thr)[0].item()

        x = np.log10(freq[f1:f2+1])
        y = np.log10(psd_i[f1:f2+1])
        s = np.polyfit(x,y,1)

        yfit = 10**np.polyval(s, x)
        beta[i] = -s[0]
        
        psd_i = psd_i[:1022]
        '''
        plt.figure(figsize = [8,6])
        plt.loglog(freq,psd_i)
        plt.loglog(freq[f1:f2+1],psd_i[f1:f2+1],'g')
        plt.loglog(freq[f1:f2+1],yfit,'r')
        plt.xlim((10**-4,1))
        plt.ylim((10**-4,100))
        plt.xlabel('frequency (1/pixels)')
        plt.ylabel('PSD')
        plt.title(f'Beta = {beta}')
        '''
    return beta

def calc_xc_yc(img):
        x,y = img.shape
        x = np.arange(x)
        y = np.arange(y)
        xx, yy = np.meshgrid(x, y)
        xc = -xx + np.mean(xx)
        yc = yy - np.mean(yy)
        return xc, yc

def cart2pol(x, y):
        rho = np.sqrt(x**2 + y**2)
        phi = np.arctan2(y, x)
        return(rho, phi)


def process_image(data):
    data1 = data[0]#np.squeeze(data[0],axis=0)
    img = equalize_adapthist(data1, clip_limit=0.01)
    #plt.figure(figsize=(10,10))
    #plt.imshow(img)
    filt = mask_stack(data,thresh_multiplier=20)
    bw = remove_nuclei_intercellular_space(data, num_hists=4, thresh_multiplier=0.8)
    mask = np.logical_and.reduce((bw, ~filt))
    remove_small_objects(mask, min_size=10, connectivity=8, in_place=True)
    mask1 = mask[0]#np.squeeze(mask,axis=0)
    #plt.figure(figsize=(10,10))
    #plt.imshow(mask1)
    data[~mask] = 0
    circular_mask = createcircularmask(data.shape[1],data.shape[2],radius=482)
    _,circularmask3d = np.broadcast_arrays(data, circular_mask)
    data[~circularmask3d] = 0
    beta = analyze(data)
    return beta




if __name__ == "__main__":
    print("...")
    parser = argparse.ArgumentParser(description='Compare stacks')
    parser.add_argument('--config',required= True, type=str, nargs=1,
                    help='Path to config file')
    args = parser.parse_args()
    print("......................")
    print(args.config[0])
    f = open(args.config[0],'rb')
    config = json.load(f)

    base_path = config["base_path"]
    filenames = ast.literal_eval(config["filenames"])
    labels = ast.literal_eval(config["file_labels"])



    data_denoised = load('D:\\work\\Research\\Denoising\\Data\\all_hysterectomy\\results\\755\\20191121_Series012\\restored_ch01_4_64_64.tif')
    data_denoised = data_denoised / np.max(np.abs(data_denoised))
    betas_denoised = []

    data_noisy = load('D:\\work\\Research\\Denoising\\Data\\all_hysterectomy\\results\\755\\20191121_Series012\\ch01.tif')
    data_noisy = data_noisy / np.max(np.abs(data_noisy))
    betas_noisy = []

    data_avg = load('D:\\work\\Research\\Denoising\\Data\\all_hysterectomy\\results\\755\\20191121_Series012\\Hysterectomy_20191121_Series012_NADH_shift_stack.tiff')
    data_avg = data_avg / np.max(np.abs(data_avg))
    betas_avg = []
    print(len(data_avg))

    n = 100
    beta = process_image(data_denoised[:n])
    print(beta)
    '''
    for denoised,noisy,avg in zip(data_denoised[:n],data_noisy[:n],data_avg[:n]):
        betas_denoised.append(process_image(np.expand_dims(denoised,axis=0)))
        betas_noisy.append(process_image(np.expand_dims(noisy,axis=0)))
        betas_avg.append(process_image(np.expand_dims(avg,axis=0)))
    '''  
  
    import pandas as pd

    df = pd.DataFrame()
    df["Noisy"] = np.array(betas_noisy).flatten()
    df["Denoised"] = np.array(betas_denoised).flatten()
    df["Average"] = np.array(betas_avg).flatten()
    df.to_csv("D:\\work\\Research\\Denoising\\Data\\all_hysterectomy\\results\\755\\20191121_Series012\\betas.csv")
    